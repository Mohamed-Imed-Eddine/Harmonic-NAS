small_dataset: False

pretrained_path1 : "./saved_supernets/AV-MNIST/supernet_avmnist_image.pth.tar"
pretrained_path2 : "./saved_supernets/AV-MNIST/supernet_avmnist_sound.pth.tar"


hw_lut_path: "./evaluate/backbone_eval/efficiency/lut_ofa_mnist_tx2.json"
fusion_lut: "./evaluate/fusion_eval/lut_fusion_tx2.json"


# Search hyperparameters
evo_search_outer:
    parent_popu_size: 8
    survival_ratio: .5
    mutate_size: 64
    crossover_size: 64
    mutate_prob: 0.4
    crossover_prob: 0.8
    evo_iter: 30

evo_search_inner:
    survival_ratio: 0.25


# Fusion search parameters
fusion_epochs: 25

C : 192
L : 16
multiplier : 2

node_multiplier : 1

num_outputs : 10
drpt : 0.1

# num_input_nodes : 8
num_keep_edges : 2

arch_learning_rate : 0.0003
arch_weight_decay : 0.001

weight_decay : 0.0001
eta_max : 0.0001 
eta_min : 0.000001
Ti : 1
Tm : 2

parallel : False
save : ''



# supernet_arch: 'supernet_dynamic_model'


supernet_arch: 'ofa'
arch: 'supernet_dynamic_model'


exp_name: "unimodal_supernet_avmnist_image"
resume: ""

batch_size_per_gpu: 256
batch_size : 256
sandwich_rule: True

alpha_min: -1.0
alpha_max: 1.0
iw_clip: 5.0

grad_clip_value: 1.0

augment: "auto_augment_tf"

n_gpu_per_node: 8
num_nodes: 8
n_cpu_per_node: 32
memory_per_node: '128g'

epochs: 50
warmup_epochs: 5
start_epoch: 0

label_smoothing: 0.1
inplace_distill: False

#sync-batchnormalization, suggested to use in bignas
bn_calibration: False
sync_bn: False

bn_momentum: 0
bn_eps: 1e-5

post_bn_calibration_batch_num: 64

num_arch_training: 4

models_save_dir: "./saved_models"

#### cloud training resources  ####
data_loader_workers_per_gpu: 4

########### regularization ################
# supernet training regularization (the largest network)
dropout: 0.2
drop_connect: 0.2
drop_connect_only_last_two_stages: True

weight_decay_weight: 0.0001
weight_decay_bn_bias: 0.

## =================== optimizer and scheduler======================== #
optimizer:
    method: adam
    momentum: 0.9
    nesterov: True

lr_scheduler:
    method: "warmup_cosine_lr" 
    base_lr: 0.00001
    clamp_lr_percent: 0.0

### distributed training settings ###


distributed: False
distributed_val: False
eval_only: True
multiprocessing_distributed: True


# dist_backend: 'nccl'


### multimodal dataset ###
dataset: 'avmnist'
# Path to the 'soundmnist_data' folder
dataset_dir: "/home/imed/Desktop/datasets/AV-MNIST/"
n_classes: 10
drop_last: True
# task : ['multilabel', 'classification']
task: classification
image_resolution: 28
sound_resolution: 20
in_channels: 1

print_freq: 50
seed: 42
